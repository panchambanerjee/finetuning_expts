{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMfKQykn6DpqumHxTmq5l0m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panchambanerjee/finetuning_expts/blob/main/synthetic_data_kit_dataset_gen_2025_06_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using **synthetic-data-kit** (https://github.com/meta-llama/synthetic-data-kit/tree/main/use-cases/getting-started) to generate QA pairs for fine-tuning from a Recent interesting Cosmology + ML paper: **Learning and Interpreting Gravitational-Wave Features from CNNs with a Random Forest\n",
        "Approach** (https://arxiv.org/pdf/2505.20357)"
      ],
      "metadata": {
        "id": "xhlYOKf_i7_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also using this Unsloth notebook as reference: https://colab.research.google.com/drive/1aRRX5up1XMPR1TBn7lxnk2AHboeZqVG_#scrollTo=jxUolhgCPSr1"
      ],
      "metadata": {
        "id": "RRyfFxYckzkv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QfGzAgZzdFAM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm==0.8.2\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm==0.8.2\n",
        "\n",
        "# Get https://github.com/meta-llama/synthetic-data-kit\n",
        "!pip install synthetic-data-kit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" in \"\".join(os.environ.keys()):\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers|importlib_metadata)[^\\n]{0,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ],
      "metadata": {
        "id": "y8CSI027kyKl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.dataprep import SyntheticDataKit\n",
        "\n",
        "generator = SyntheticDataKit.from_pretrained(\n",
        "    # Choose any model from https://huggingface.co/unsloth\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
        "    max_seq_length = 2048, # Longer sequence lengths will be slower!\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6RUixW0alEAQ",
        "outputId": "6f096906-a777-4634-8bd8-2fccc352f68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 06-02 03:24:34 [__init__.py:239] Automatically detected platform cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.prepare_qa_generation(\n",
        "    output_folder = \"data\", # Output location of synthetic data\n",
        "    temperature = 0.7, # Higher temp makes more diverse datases\n",
        "    top_p = 0.95,\n",
        "    overlap = 64, # Overlap portion during chunking\n",
        "    max_generation_tokens = 512, # Can increase for longer QA pairs\n",
        ")"
      ],
      "metadata": {
        "id": "Rp9y4LrMl6WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!synthetic-data-kit system-check"
      ],
      "metadata": {
        "id": "DvcnVP8Un4pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Parse the document to generate QA Pairs\n",
        "\n",
        "# Byte Latent Transformer: Patches Scale Better Than Tokens paper in HTML format\n",
        "!synthetic-data-kit \\\n",
        "    -c synthetic_data_kit_config.yaml \\\n",
        "    ingest \"https://arxiv.org/pdf/2505.20357\"\n",
        "\n",
        "# Truncate document\n",
        "filenames = generator.chunk_data(\"data/output/arxiv_org.txt\")\n",
        "print(len(filenames), filenames[:3])"
      ],
      "metadata": {
        "id": "fXUp93qRn_70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see around 2256 chunks of data. We now call synthetic-data-kit to create some pairs of data for 50 of our chunks.\n",
        "\n",
        "\n",
        "\n",
        "Using `--num-pairs` will generate **approximately** that many QA pairs. However it might be shorter or longer depending on the `max_seq_length` of the loaded up model."
      ],
      "metadata": {
        "id": "ekbzupoUoyry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Process 5 chunks for now -> can increase but slower!\n",
        "for filename in filenames[:5]:\n",
        "    !synthetic-data-kit \\\n",
        "        -c synthetic_data_kit_config.yaml \\\n",
        "        create {filename} \\\n",
        "        --num-pairs 25 \\\n",
        "        --type \"qa\"\n",
        "    time.sleep(2) # Sleep some time to leave some room for processing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YpCL8yQoUtL",
        "outputId": "e960e16c-0bed-440e-c882-1c69175dcb59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2KProcessing 1 chunks to generate QA pairs...\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 16 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/arxiv_org_0_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/arxiv_org_0_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/output/arxiv_org_0.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/arxiv_org_0_qa_pairs.json\u001b[0m\n",
            "\u001b[2KProcessing 1 chunks to generate QA pairs...\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 15 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/arxiv_org_1_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/arxiv_org_1_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/output/arxiv_org_1.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/arxiv_org_1_qa_pairs.json\u001b[0m\n",
            "\u001b[2KProcessing 1 chunks to generate QA pairs...\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 14 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/arxiv_org_2_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/arxiv_org_2_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/output/arxiv_org_2.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/arxiv_org_2_qa_pairs.json\u001b[0m\n",
            "\u001b[2KProcessing 1 chunks to generate QA pairs...\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 18 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/arxiv_org_3_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/arxiv_org_3_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/output/arxiv_org_3.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/arxiv_org_3_qa_pairs.json\u001b[0m\n",
            "\u001b[2KProcessing 1 chunks to generate QA pairs...\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 16 QA pairs total\n",
            "\u001b[2KSaving result to data/generated/arxiv_org_4_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to data/generated/arxiv_org_4_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/output/arxiv_org_4.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m Content saved to \u001b[0m\u001b[1;32mdata/generated/arxiv_org_4_qa_pairs.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, we can clean up the data via pruning \"bad\" or low quality examples and convert the rest to JSON format for finetuning!\n",
        "\n",
        "# !synthetic-data-kit \\\n",
        "#     -c synthetic_data_kit_config.yaml \\\n",
        "#     curate --threshold 0.0 \\\n",
        "#     \"data/generated/arxiv_org_0_qa_pairs.json\""
      ],
      "metadata": {
        "id": "XpfFLfQVo_F9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the generated datasets into QA formats so we can load it for finetuning\n",
        "\n",
        "qa_pairs_filenames = [\n",
        "    f\"data/generated/arxiv_org_{i}_qa_pairs.json\"\n",
        "    for i in range(len(filenames[:3]))\n",
        "]\n",
        "for filename in qa_pairs_filenames:\n",
        "    !synthetic-data-kit \\\n",
        "        -c synthetic_data_kit_config.yaml \\\n",
        "        save-as {filename} -f ft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrBqhKjzs9NC",
        "outputId": "00a58f19-7e3c-4965-d7dd-99ac3995aede"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/arxiv_org_0_qa_pairs.json to ft format with json \n",
            "storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\u001b[1;32mdata/final/arxiv_org_0_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/arxiv_org_1_qa_pairs.json to ft format with json \n",
            "storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\u001b[1;32mdata/final/arxiv_org_1_qa_pairs_ft.json\u001b[0m\n",
            "\u001b[?25l\u001b[32m‚†ã\u001b[0m Converting data/generated/arxiv_org_2_qa_pairs.json to ft format with json \n",
            "storage...\n",
            "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32m Converted to ft format and saved to \u001b[0m\u001b[1;32mdata/final/arxiv_org_2_qa_pairs_ft.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "final_filenames = [\n",
        "    f\"data/final/arxiv_org_{i}_qa_pairs_ft.json\"\n",
        "    for i in range(len(filenames[:3]))\n",
        "]\n",
        "conversations = pd.concat([\n",
        "    pd.read_json(name) for name in final_filenames\n",
        "]).reset_index(drop = True)\n",
        "\n",
        "dataset = Dataset.from_pandas(conversations)"
      ],
      "metadata": {
        "id": "9i1wlSmnuBs9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVcmWqwEuF6r",
        "outputId": "cb6a5417-3346-4f58-b8e7-607111a8b1e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIRxwnzpuI4q",
        "outputId": "cbd31f31-2b55-4969-8477-a532cbd9e06d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/final/arxiv_org_0_qa_pairs_ft.json',\n",
              " 'data/final/arxiv_org_1_qa_pairs_ft.json',\n",
              " 'data/final/arxiv_org_2_qa_pairs_ft.json']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6um21-4uNSl",
        "outputId": "1c6ac74a-ccc6-4b98-a195-fa742c90918b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'Who are the authors of the PDF document?', 'role': 'user'},\n",
              "  {'content': 'Jun Tian; He Wang; Jibo He; Yu Pan; Shuo Cao; Qingquan Jiang',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QyWrIVcuiid",
        "outputId": "69eed47f-258a-499b-d13c-dac61072c3fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What is the title of the PDF document?', 'role': 'user'},\n",
              "  {'content': 'Learning and Interpreting Gravitational-Wave Features from CNNs with a Random Forest Approach',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT7a1YZjumFD",
        "outputId": "a8903723-e639-4402-b7fa-2a0c4560ebb1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What is the DOI of the PDF document?', 'role': 'user'},\n",
              "  {'content': 'https://doi.org/10.48550/arXiv.2505.20357',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmvLhJj0um9r",
        "outputId": "3f627b9f-8aba-43be-be9e-fb3f94f73cc2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'How many bytes does the metadata object contain?',\n",
              "   'role': 'user'},\n",
              "  {'content': '1769', 'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gxG8IB0uob8",
        "outputId": "7aa061a3-bccc-42ec-e88f-f96bacc044f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'How many outlines are in the outline object?', 'role': 'user'},\n",
              "  {'content': '1', 'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_FwQVSzuqwV",
        "outputId": "3356f435-1dac-4a26-8f11-832101901476"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
              "  {'content': 'What is the D value of the 26th annot?', 'role': 'user'},\n",
              "  {'content': '(cite.2019PhRvX...9c1040A)', 'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.cleanup()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6bl13mausdC",
        "outputId": "a7062308-13fb-4cb3-92cd-462e5069b7a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to terminate the VLLM server gracefully...\n",
            "Server terminated gracefully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JINPwyXu0NF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}